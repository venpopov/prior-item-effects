#############################################################################
rm(list=ls())
library(tidyverse)
library(here)
library(lme4)
library(cowplot)
source(here('analyses/prior_item_functions.R'))
theme_set(theme_bw(base_size=8))
#############################################################################
# split into study and test, extract info about prior item freq during study
# then join with test
# The original dataset is available from https://osf.io/dd8kp/. The csv file below
# contains the same data with light preprocessing.
dat <- read.csv(here('data/cox2018.csv'))
dat$acc <- ifelse(!is.na(dat$resp.type.rescore) & (dat$resp.type.rescore == "Hit" | dat$resp.type.rescore == 'CR'),
1,
as.numeric(dat$resp.type == 'Hit' | dat$resp.type == 'CR'))
# Get SUBTLEX WORD FREQUENCY
freq <- read.csv(here('materials/SUBTLEX_all_words.csv'))
freq <- freq %>% select(Word, Lg10WF) %>% mutate(Word = toupper(Word))
dat <- dat %>%
select(-freq1, -freq2) %>%
left_join(freq, by=c('stim1'='Word')) %>%
left_join(freq, by=c('stim2'='Word'), suffix=c('1','2')) %>%
rename('freq1'='Lg10WF1', 'freq2'='Lg10WF2')
# remove unfinished blocks
dat <- dat %>%
group_by(subject, procedure, block) %>%
mutate(count = length(block)) %>%
filter(!(count != 20 & condition != 'Free recall')) %>%
ungroup()
# extract the average frequency of the preceding study item
study <- dat %>%
filter(procedure == 'study') %>%
select(subject, block, condition, stim1, stim2, freq1, freq2) %>%
mutate(freq = (freq1+freq2)/2) %>%
group_by(subject, block) %>%
prior_item_analysis('freq','freq',NULL, max_lag = 1) %>%
mutate_at(vars(contains('freq')), as.numeric) %>%
select(-freq_prioritem1)
# mutate(freq_prioritem = (freq_prioritem1+freq_prioritem2+freq_prioritem3)/3) %>%
# select(-freq_prioritem1,-freq_prioritem2,-freq_prioritem3)
test <- dat %>%
filter(procedure == 'test') %>%
mutate(resp.string = toupper(resp.string))
dat <- test %>%
filter(condition != 'Free recall', condition != 'Lexical decision') %>%
ungroup() %>%
left_join(study %>% select(-stim2, -freq1, -freq2, -freq, -condition), by=c('subject','stim1', 'block')) %>%
left_join(study %>% select(-stim1, -freq1, -freq2, -freq, -condition), by=c('subject','stim2', 'block')) %>%
left_join(study %>% select(-stim1, -freq1, -freq2, -freq, -condition), by=c('subject','stim1'='stim2', 'block')) %>%
left_join(study %>% select(-stim2, -freq1, -freq2, -freq, -condition), by=c('subject','stim2'='stim1', 'block'))
dat$freq_prioritem <- dat %>% select(contains('prioritem')) %>% rowMeans(na.rm=T)
# dat <- dat %>% select(-freq_prioritem.x, -freq_prioritem.y, -freq_prioritem.x.x, -freq_prioritem.y.y)
# do the same for free recall
free <- study %>%
filter(condition == 'Free recall') %>%
left_join(select(test, subject, block, condition, resp.string, acc, rt), by=c('condition','subject','block','stim1'='resp.string')) %>%
left_join(select(test, subject, block, condition, resp.string, acc, rt), by=c('condition','subject','block','stim2'='resp.string'), suffix=c('1','2')) %>%
mutate(acc1 = ifelse(is.na(acc1),0,1),
acc2 = ifelse(is.na(acc2),0,1),
acc = acc1+acc2,
rt = ifelse(is.na(rt1), rt2, rt1)) %>%
select(-acc1,-acc2,-freq, -rt1, -rt2)
#combine free recall witht he others
dat <- bind_rows(dat, free) %>%
arrange(subject, block)
dat$condition <- dat$condition %>% tolower()
dat$stim1 <- dat$stim1 %>% tolower()
sac_fit <- read.csv('output/cox2018_sac_model_fit.csv')
# fix free recall accuracy, because here it's coded as 2 for recalling the pair
sac_fit[sac_fit$condition == 'free recall',]$acc_pred <- sac_fit[sac_fit$condition == 'free recall',]$acc_pred*2
ml2 <- glmer(acc ~ condition + freq_prioritem + (1|subject) +(1|stim1), data=mldata, family='binomial', nAGQ=0)
#############################################################################
# ANALYSES
#############################################################################
mldata <- filter(dat, resp.type %in% c("Hit",'Miss') | condition == "free recall", !is.na(freq_prioritem)) %>% mutate(acc = as.numeric(acc>0))
ml2 <- glmer(acc ~ condition + freq_prioritem + (1|subject) +(1|stim1), data=mldata, family='binomial', nAGQ=0)
summary(ml2)
ml1 <- glmer(acc ~ condition + (1|subject) +(1|stim1), data=mldata, family='binomial', nAGQ=0)
ml3 <- glmer(acc ~ condition*freq_prioritem + (1|subject) +(1|stim1), data=mldata, family='binomial', nAGQ=0)
anova(ml1,ml2)
anova(ml2,ml3)
#############################################################################
# split into study and test, extract info about prior item freq during study
# then join with test
dat <- read.csv(here('data/cox2018.csv'))
# dat$acc <- ifelse(!is.na(dat$resp.type.rescore) & (dat$resp.type.rescore == "Hit" | dat$resp.type.rescore == 'CR'), 1, as.numeric(dat$resp.type == 'Hit' | dat$resp.type == 'CR'))
freq <- read.csv(here('materials/SUBTLEX_all_words.csv'))
freq <- freq %>% select(Word, Lg10WF) %>% mutate(Word = toupper(Word))
dat <- dat %>%
select(-freq1, -freq2) %>%
left_join(freq, by=c('stim1'='Word')) %>%
left_join(freq, by=c('stim2'='Word'), suffix=c('1','2')) %>%
rename('freq1'='Lg10WF1', 'freq2'='Lg10WF2')
# remove unfinished blocks
dat <- dat %>%
group_by(subject, procedure, block) %>%
mutate(count = length(block)) %>%
filter(!(count != 20 & condition != 'Free recall')) %>%
ungroup()
study <- dat %>%
filter(procedure == 'study') %>%
select(subject, block, condition, stim1, stim2, freq1, freq2) %>%
mutate(freq = (freq1+freq2)/2) %>%
group_by(subject, block) %>%
prior_item_analysis('freq','freq',NULL, max_lag = 3) %>%
mutate_at(vars(contains('freq')), as.numeric)
test <- dat %>%
filter(procedure == 'test') %>%
mutate(resp.string = toupper(resp.string))
dat <- test %>%
filter(condition != 'Free recall', condition != 'Lexical decision') %>%
ungroup() %>%
left_join(study %>% select(-stim2, -freq1, -freq2, -condition), by=c('subject','stim1', 'block')) %>%
left_join(study %>% select(-stim1, -freq1, -freq2, -condition), by=c('subject','stim2', 'block')) %>%
left_join(study %>% select(-stim1, -freq1, -freq2, -condition), by=c('subject','stim1'='stim2', 'block')) %>%
left_join(study %>% select(-stim2, -freq1, -freq2, -condition), by=c('subject','stim2'='stim1', 'block'))
dat$freq_prioritem1 <- dat %>% select(contains('prioritem1')) %>% rowMeans(na.rm=T)
dat$freq_prioritem2 <- dat %>% select(contains('prioritem2')) %>% rowMeans(na.rm=T)
dat$freq_prioritem3 <- dat %>% select(contains('prioritem3')) %>% rowMeans(na.rm=T)
dat$freq_current <- dat %>% select(contains('freq.')) %>% rowMeans(na.rm=T)
# dat$freq_prioritem4 <- dat %>% select(contains('prioritem4')) %>% rowMeans(na.rm=T)
dat <- dat %>% select(-contains('.x'), -contains('.y'))
# do the same for free recall
free <- study %>%
filter(condition == 'Free recall') %>%
left_join(select(test, subject, block, condition, resp.string, acc, rt), by=c('condition','subject','block','stim1'='resp.string')) %>%
left_join(select(test, subject, block, condition, resp.string, acc, rt), by=c('condition','subject','block','stim2'='resp.string'), suffix=c('1','2')) %>%
mutate(freq_current = (freq1+freq2)/2) %>%
mutate(acc1 = ifelse(is.na(acc1),0,1),
acc2 = ifelse(is.na(acc2),0,1),
acc = acc1+acc2,
rt = ifelse(is.na(rt1), rt2, rt1)) %>%
select(-acc1,-acc2,-freq, -rt1, -rt2)
#combine free recall witht he others
dat <- bind_rows(dat, free) %>%
arrange(subject, block)
dat$condition <- dat$condition %>% tolower()
dat$stim1 <- dat$stim1 %>% tolower()
sac_fit <- read.csv('output/cox2018_results_fit.csv')
# fix free recall accuracy, because here it's coded as 2 for recalling the pair
sac_fit[sac_fit$condition == 'free recall',]$acc_pred <- sac_fit[sac_fit$condition == 'free recall',]$acc_pred*2
sac_fit <- read.csv('output/cox2018_sac_model_fit.csv')
# fix free recall accuracy, because here it's coded as 2 for recalling the pair
sac_fit[sac_fit$condition == 'free recall',]$acc_pred <- sac_fit[sac_fit$condition == 'free recall',]$acc_pred*2
(f1 <- dat %>%
left_join(select(sac_fit, subject, condition, stim1, acc_pred)) %>%
filter(resp.type.rescore %in% c("Hit",'Miss') | condition == 'free recall' | condition == 'single recognition', !is.na(freq_prioritem1), !is.na(freq_prioritem2), !is.na(freq_prioritem3)) %>%
gather(lag, freq_prioritems, freq_prioritem1, freq_prioritem2, freq_prioritem3) %>%
mutate(freq_prioritem_cat = cut(freq_prioritems, quantile(freq_prioritems, probs=seq(0,1,length.out=30)), include.lowest = TRUE),
freq_prioritem_cat = as.numeric(freq_prioritem_cat)) %>%
group_by(freq_prioritem_cat, lag, condition) %>%
summarise(acc = mean(acc, na.rm=T),
acc_pred = mean(acc_pred, na.rm=T),
rt = mean(rt, na.rm=T),
IES = rt/acc,
freq_prioritem = mean(freq_prioritems) %>% round(3)) %>%
group_by(freq_prioritem_cat, lag) %>%
summarise(acc = mean(acc, na.rm=T),
acc_pred = mean(acc_pred, na.rm=T),
rt = mean(rt, na.rm=T),
IES = mean(IES, na.rm=T),
freq_prioritem = mean(freq_prioritem) %>% round(3)) %>%
ungroup() %>%
gather(data, acc, acc, acc_pred) %>%
mutate(data = recode(data, acc='Observed', acc_pred='SAC Model fit')) %>%
ggplot(aes(log(10^(freq_prioritem)/51), acc, color=lag)) +
geom_point(size=1) +
geom_smooth(se=FALSE, method='lm') +
theme_bw() +
theme(panel.grid = element_blank(),
panel.spacing = unit(1,'lines'),
legend.position = 'bottom') +
scale_x_continuous('Mean log(freq) of preceding item during study', breaks = seq(1,4,0.5), limits = c(1,4.2)) +
scale_color_discrete('Prior item lag', labels=c(1,2,3)) +
ylab('Hit rate') +
coord_cartesian(ylim=c(0.35,0.46)) +
facet_wrap(~data))
#############################################################################
rm(list=ls())
library(tidyverse)
library(here)
library(lme4)
library(cowplot)
source(here('analyses/prior_item_functions.R'))
theme_set(theme_classic(base_size=9))
#############################################################################
# split into study and test, extract info about prior item freq during study
# then join with test
dat <- read.csv(here('data/diana2006_exp1.csv'))
dat$freq <- tolower(dat$freq)
study <- dat %>%
filter(procedure == 'study') %>%
select(subject, stim1, stim2, freq) %>%
group_by(subject) %>%
prior_item_analysis('freq','freq','low',4, 3)
test <- dat %>%
filter(procedure == 'test') %>%
select(subject, stim1, rt, trial,resp, rem, fam, new, acc)
dat <- study %>%
ungroup() %>%
left_join(test, by=c('subject','stim1')) %>%
filter(!is.na(freq_prioritem1),
!(subject %in% c(9,20)))  # remove subjects with below chance performance
# load modelling results
# sac_fit <- read.csv('output/diana2006_model_fit.csv')
sac_fit <- read.csv('output/diana2006_results_fit_mult.csv')
# load modelling results
# sac_fit <- read.csv('output/diana2006_model_fit.csv')
sac_fit <- read.csv('output/diana2006_sac_model_fit.csv')
# accuracy by freq and freq_prioritem
(f1 <- dat %>%
ggplot(aes(freq, acc, fill=freq_prioritem, group=freq_prioritem)) +
stat_summary(fun.data = mean_se, geom="col", position='dodge', width=0.3) +
stat_summary(fun.data = mean_se, geom="errorbar", width=0.1, position=position_dodge(0.3)) +
scale_x_discrete(name='Frequency of the current item\n') +
scale_fill_discrete(name='Frequency of the preceeding\nitem during encoding') +
scale_y_continuous(name='Hit rate') +
coord_cartesian(ylim=c(0.5,1.05)) +
theme_classic() +
theme(legend.position = c(1,1),
legend.justification = c(1,1)))
# accuracy by freq and freq_prioritem
(f1 <- dat %>%
ggplot(aes(freq, acc, fill=freq_prioritem, group=freq_prioritem)) +
stat_summary(fun.data = mean_se, geom="col", position='dodge', width=0.3) +
stat_summary(fun.data = mean_se, geom="errorbar", width=0.2, position=position_dodge(0.3)) +
scale_x_discrete(name='Frequency of the current item\n') +
scale_fill_discrete(name='Frequency of the preceeding\nitem during encoding') +
scale_y_continuous(name='Hit rate') +
coord_cartesian(ylim=c(0.5,1.05)) +
theme_classic() +
theme(legend.position = c(1,1),
legend.justification = c(1,1)) +
stat_summary(data=sac_fit, aes(y=old_pred), geom='point', position=position_dodge(0.3), size=2))
# cumulative effect of freq_consec
pred <- sac_fit %>%
group_by(freq, freq_consec_lab) %>%
summarise(old_pred = mean(old_pred, na.rm=T))
(f2 <- dat %>%
left_join(pred) %>%
gather(variable, value, acc, old_pred) %>%
mutate(freq = recode(freq, high = 'HF current item', low='LF current item')) %>%
mutate(variable = recode(variable, acc = 'Data', old_pred = 'SAC model fit')) %>%
ggplot(aes(freq_consec_value, value, shape=variable, linetype=variable, fill=variable)) +
stat_summary(geom='line') +
stat_summary(fun.data = mean_se, geom="point", size=2.5) +
# stat_summary(fun.data = mean_se, geom="line") +
scale_x_continuous(name='Number of consecutive LOW or HIGH\n frequency preceding items', breaks=sort(unique(dat$freq_consec_value)),
labels=c('LF4','LF3','LF2','LF1','HF1','HF2','HF3','HF4')) +
scale_y_continuous(name='Hit rate') +
scale_shape_manual(name='', values=c(21,24)) +
scale_fill_manual(name='', values=c('black','white')) +
scale_linetype_discrete(name='') +
theme_bw(base_size=10) +
theme(legend.position = c(0.95,0.05),
legend.justification = c(1,0),
panel.spacing.x = unit(1, 'lines'),
panel.grid = element_blank()) +
facet_wrap(~freq))
#############################################################################
rm(list=ls())
library(tidyverse)
library(here)
library(lme4)
source(here('analyses/prior_item_functions.R'))
#############################################################################
dat <- read.csv(here('data/reder2002_exp1.csv'))
study <- dat %>%
filter(procedure == 'studyrecog') %>%
select(subject, session, freq,stim) %>%
mutate(freq = ifelse(freq == 'HF','HF','LF')) %>%
group_by(subject, session) %>%
prior_item_analysis('freq','freq','LF',3)
test <- dat %>%
filter(procedure == 'testrecog') %>%
select(-recall, -nrecall, -duration, -onset,-freq) %>%
left_join(ungroup(study), by=c('subject','session','stim')) %>%
filter(!is.na(freq_prioritem))
#############################################################################
# MAIN PLOTS
#############################################################################
# IES by freq and freq_prioritem
test %>%
group_by(subject, freq, freq_prioritem) %>%
mutate(acc_mean = mean(acc),
ies = rt/acc_mean) %>%
filter(acc == 1) %>%
group_by(subject) %>%
mutate(outlier = abs(rt-median(rt, na.rm=T))/mad(rt, na.rm=T)) %>%
filter(outlier <= 4) %>%
ggplot(aes(freq, ies, fill=freq_prioritem)) +
stat_summary(fun.data = mean_se, geom="col", position='dodge', width=0.3) +
stat_summary(fun.data = mean_se, geom="errorbar", width=0.1, position=position_dodge(0.3)) +
scale_x_discrete(name='Frequency of the recalled item') +
scale_fill_discrete(name='Frequency of the preceeding\nitem during encoding') +
scale_y_continuous(name='IES (RTs/accuracy)') +
coord_cartesian(ylim=c(1200,2300)) +
theme_classic() +
theme(legend.position = c(1,1),
legend.justification = c(1,1))
# IES by freq_consec_value
test %>%
group_by(subject, freq, freq_consec_value) %>%
mutate(acc_mean = mean(acc),
ies = rt/acc_mean) %>%
filter(acc == 1) %>%
group_by(subject, freq_consec_value) %>%
mutate(outlier = abs(rt-median(rt, na.rm=T))/mad(rt, na.rm=T)) %>%
filter(outlier <= 4) %>%
ggplot(aes(freq_consec_lab, ies, group=1)) +
stat_summary(geom='pointrange') +
stat_smooth(method='lm', se=FALSE) +
scale_y_continuous(name='IES (RTs/accuracy)') +
scale_x_discrete(name='Number of consecutive LOW or HIGH\n frequency preceding items') +
theme_classic()
#############################################################################
# ADDITIONAL PLOTS
#############################################################################
# accuracy by freq and freq_prioritem
test %>%
ggplot(aes(freq, acc, fill=freq_prioritem)) +
stat_summary(fun.data = mean_se, geom="col", position='dodge', width=0.3) +
stat_summary(fun.data = mean_se, geom="errorbar", width=0.1, position=position_dodge(0.3)) +
scale_x_discrete(name='Frequency of the current item') +
scale_fill_discrete(name='Frequency of the preceeding\nitem during encoding') +
scale_y_continuous(name='Proportion recalled') +
coord_cartesian(ylim=c(0.5,1)) +
theme_classic() +
theme(legend.position = c(1,1),
legend.justification = c(1,1))
# rts by freq and freq_prioritem
test %>%
group_by(subject) %>%
mutate(outlier = abs(rt-median(rt, na.rm=T))/mad(rt, na.rm=T)) %>%
filter(acc == 1, outlier <= 4) %>%
ggplot(aes(freq, rt, fill=freq_prioritem)) +
stat_summary(fun.data = mean_se, geom="col", position='dodge', width=0.3) +
stat_summary(fun.data = mean_se, geom="errorbar", width=0.1, position=position_dodge(0.3)) +
scale_x_discrete(name='Frequency of the recalled item') +
scale_fill_discrete(name='Frequency of the preceeding\nitem during encoding') +
scale_y_continuous(name='RTs') +
coord_cartesian(ylim=c(1200,1700)) +
theme_classic() +
theme(legend.position = c(1,1),
legend.justification = c(1,1))
# rts by freq_consec
test %>%
group_by(subject) %>%
mutate(outlier = abs(rt-median(rt, na.rm=T))/mad(rt, na.rm=T)) %>%
filter(acc == 1, outlier <= 4) %>%
ggplot(aes(freq_consec_lab, rt, group=1)) +
stat_summary(geom='pointrange') +
stat_summary(geom='line') +
theme_classic()
# acc by freqconsec
test %>%
filter(abs(freq_consec_value) <= 2) %>%
group_by(subject) %>%
ggplot(aes(freq_consec_lab, acc, group=1)) +
stat_summary(geom='pointrange') +
stat_summary(geom='line') +
scale_x_discrete(name='Number of consecutive LOW or HIGH frequency\npreceding items') +
theme_classic()
#############################################################################
rm(list=ls())
library(tidyverse)
library(here)
library(lme4)
library(cowplot)
source(here('analyses/prior_item_functions.R'))
mean_se2 <- function (x) {
x <- stats::na.omit(x)
se <- 1.96 * sqrt(stats::var(x)/length(x))
mean <- mean(x)
data.frame(y = mean, ymin = mean - se, ymax = mean + se)
}
theme_set(theme_classic(base_size=8))
#############################################################################
# split into study and test, extract info about prior item freq during study
# then join with test
dat <- read.csv(here('data/ward2003_exp3.csv'))
names(dat) <- tolower(names(dat))
names(dat)[names(dat) == 'correct'] <- 'acc'
dat <- dat %>%
mutate(composition = recode(trialtype, l = 'pure', h='pure',m='mixed')) %>%
arrange(subject, list, nominal.sp) %>%
group_by(subject, list) %>%
prior_item_analysis('freq','freq','LOW',4, 3) %>%
filter(!is.na(freq_prioritem))
# nominal.sp > 2, nominal.sp < 15) # remove buffer items bc of recency/primacy
fit <- read.csv('output/ward2003_model_fit.csv')
fit <- mutate(fit, freq = toupper(freq),
freq_prioritem = toupper(freq_prioritem))
fit <- read.csv('output/ward2003_sac_model_fit.csv')
fit <- mutate(fit, freq = toupper(freq),
freq_prioritem = toupper(freq_prioritem))
# accuracy by freq and freq_prioritem
(f1 <- dat %>%
filter(trialtype == 'm') %>%
ggplot(aes(freq, acc, fill=freq_prioritem, group=freq_prioritem)) +
stat_summary(fun.data = mean_se, geom="col", position='dodge', width=0.3) +
stat_summary(fun.data = mean_se, geom="errorbar", width=0.1, position=position_dodge(0.3)) +
scale_x_discrete(name='Frequency of the recalled item') +
scale_fill_discrete(name='Frequency of the preceeding\nitem during encoding') +
scale_y_continuous(name='b) Proportion recalled') +
coord_cartesian(ylim=c(0.1,0.6)) +
ggtitle('') +
theme(legend.position = c(1,1),
legend.justification = c(1,1)) +
stat_summary(data=fit, aes(y=acc_pred), geom='point', position=position_dodge(0.3), size=1.5))
# cumulative effect of freq_consec
dat %>%
filter(abs(freq_consec_value) <= 3, nominal.sp > 2, nominal.sp < 15) %>%
filter(trialtype == 'm') %>%
ggplot(aes(freq_consec_lab, acc, group=freq, color=freq)) +
stat_summary(fun.data = mean_se, geom="pointrange") +
stat_smooth(method='lm', se=FALSE) +
scale_x_discrete(name='Number of consecutive LOW or HIGH\n frequency preceding items') +
scale_color_discrete(name='Frequency of the current item') +
scale_y_continuous(name='Proportion recalled') +
theme(legend.position = c(1,1),
legend.justification = c(1,1))
# number of rehearsals by freq and freq_prioritem
(f2 <- dat %>%
filter(trialtype == 'm', nominal.sp > 2, nominal.sp < 15) %>%
ggplot(aes(freq, rehearsals, fill=freq_prioritem, group=freq_prioritem)) +
stat_summary(fun.data = mean_se, geom="col", position='dodge', width=0.3) +
stat_summary(fun.data = mean_se, geom="errorbar", width=0.1, position=position_dodge(0.3)) +
scale_x_discrete(name='Frequency of the recalled item') +
scale_fill_discrete(name='Frequency of the preceeding\nitem during encoding') +
scale_y_continuous(name='c) Number of rehearsals') +
coord_cartesian(ylim=c(2,3.8)) +
ggtitle('') +
theme(legend.position = c(1,1),
legend.justification = c(1,1)))
(f3 <- dat %>%
filter(composition != '') %>%
ggplot(aes(composition, acc, fill=freq)) +
stat_summary(fun.data = mean_se2, geom="col", position='dodge', width=0.3) +
stat_summary(fun.data = mean_se2, geom="errorbar", width=0.1, position=position_dodge(0.3)) +
stat_summary(data=fit, aes(y=acc_pred), geom='point', position=position_dodge(0.3), size=1.5) +
scale_x_discrete('List composition') +
scale_y_continuous('a) Proportion recalled') +
scale_fill_manual('Frequency of the recalled item', values=c('dodgerblue2','darkorange1')) +
coord_cartesian(ylim=c(0.1,0.75)) +
ggtitle('Ward et al (2003; Exp. 3)') +
theme(legend.position = c(1,1),
legend.justification = c(1,1),
title = element_text(size=8)))
